- Initialized Node.js project with TypeScript, ESLint, and Prettier
- Created CLI entry point with yargs for command handling
- Implemented basic REPL interface with prompts library
- Developed minimal queryAI function with streaming capability
- Set up project structure and documentation
- Integrated Ollama API for AI responses
- Added configuration management with environment variables
- Implemented error handling for AI queries
- Added test-connection command for verifying Ollama connectivity
- Designed and implemented Tool interface with clear typing
- Created tool registry for managing and accessing tools
- Implemented filesystem tools (listDir, readFile) with security checks
- Added command parsing in REPL for executing tools
- Implemented agent mode where AI can autonomously use tools
- Created tool call format parsing and execution in agent mode
- Added conversation history management with tool calls and results
- Enhanced agent mode with proper JSON tool calling for llama3.1:latest model
- Implemented multiple fallback approaches for tool calling
- Added debug mode for diagnosing AI interactions
- Fixed tool call format parsing to handle llama3.1's specific JSON structure
- Added robust multi-strategy parsing to ensure tool calls are properly detected
